{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d05a96c-7a75-46d4-a04e-3163771da0d4",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e1eedf2-5ec1-45e1-93c5-91cea18f463e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T06:06:46.063764Z",
     "iopub.status.busy": "2022-04-05T06:06:46.063396Z",
     "iopub.status.idle": "2022-04-05T06:06:53.374366Z",
     "shell.execute_reply": "2022-04-05T06:06:53.373788Z",
     "shell.execute_reply.started": "2022-04-05T06:06:46.063722Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b90fcf8445244877bb8609738faa73af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = spark.read.format(\"parquet\")\\\n",
    "    .option(\"header\",\"true\")\\\n",
    "    .option(\"inferschema\",\"true\")\\\n",
    "    .load(\"s3://vitaproject23/cleandata/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0c6b8d-3021-4554-9c66-7720b254a761",
   "metadata": {},
   "source": [
    "# Drop Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0783975-e893-4b4e-b22f-c39561ea8744",
   "metadata": {},
   "source": [
    "Our aim is to predict delay at the time of Ticket booking and hence the following columns wont help us in prediction because customer will be unaware of the following data :- 'TAXI_OUT', 'TAXI_IN', 'WHEELS_OFF', 'WHEELS_ON', 'ARR_DELAY', 'DEP_DELAY', 'ACTUAL_ELAPSED_TIME', 'DEP_TIME', 'ARR_TIME'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebb18203-d331-4566-a23b-1c78d1895470",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T06:06:57.089315Z",
     "iopub.status.busy": "2022-04-05T06:06:57.089083Z",
     "iopub.status.idle": "2022-04-05T06:06:57.153213Z",
     "shell.execute_reply": "2022-04-05T06:06:57.152651Z",
     "shell.execute_reply.started": "2022-04-05T06:06:57.089292Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d0f69a7e43a433b9c4c6e916a239ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.drop('FL_DATE','TAXI_OUT','WHEELS_OFF','WHEELS_ON','TAXI_IN','ARR_DELAY','DEP_DELAY','ACTUAL_ELAPSED_TIME','DEP_TIME','ARR_TIME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6471ea64-eb61-41f0-ad78-9b807a239889",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T05:25:42.284983Z",
     "iopub.status.busy": "2022-04-05T05:25:42.284760Z",
     "iopub.status.idle": "2022-04-05T05:25:45.623642Z",
     "shell.execute_reply": "2022-04-05T05:25:45.622917Z",
     "shell.execute_reply.started": "2022-04-05T05:25:42.284960Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55feb6b52c0c46ec92d4df896ca42ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Columns:  12\n",
      "Number of Rows: 60431020"
     ]
    }
   ],
   "source": [
    "df.columns\n",
    "print(\"Number of Columns: \", len(df.columns))\n",
    "print(\"Number of Rows:\", df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8e4857-4933-4d59-8272-f44a2dfbd36c",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fac54bd3-f054-4167-b696-9e3d879e6f76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T06:02:54.061725Z",
     "iopub.status.busy": "2022-04-05T06:02:54.061480Z",
     "iopub.status.idle": "2022-04-05T06:02:54.118804Z",
     "shell.execute_reply": "2022-04-05T06:02:54.118207Z",
     "shell.execute_reply.started": "2022-04-05T06:02:54.061702Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a63bb0b16a4dd599a2004d356fbf46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer,VectorAssembler,VectorIndexer,StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad219a4-3125-4784-9990-d11f3099f6c1",
   "metadata": {},
   "source": [
    "# StringIndexer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0fa4c6-6037-42d5-a9f1-7ad7b7fc5ee2",
   "metadata": {},
   "source": [
    "- Converting Categorical Columns such as 'OP_CARRIER', 'ORIGIN', 'DEST' are converted into Indexed Columns 'OP_CARRIER_I', 'ORIGIN_I', 'DEST_I' using StringIndexer.\n",
    "- StringIndexer is used to convert categorical columns to numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abf81191-982c-4893-b645-0676be82cf7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T05:26:08.460879Z",
     "iopub.status.busy": "2022-04-05T05:26:08.460548Z",
     "iopub.status.idle": "2022-04-05T05:26:08.777218Z",
     "shell.execute_reply": "2022-04-05T05:26:08.776393Z",
     "shell.execute_reply.started": "2022-04-05T05:26:08.460841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee9de40989a4427b9c5c865a6b6b2cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indexer1 = StringIndexer(inputCol='OP_CARRIER',outputCol='OP_CARRIER_I')\n",
    "#strindexedDF1 = indexer1.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf5ee044-6ef1-4a6c-9dcd-47d660531ff9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T05:26:27.412962Z",
     "iopub.status.busy": "2022-04-05T05:26:27.412738Z",
     "iopub.status.idle": "2022-04-05T05:26:27.477788Z",
     "shell.execute_reply": "2022-04-05T05:26:27.477221Z",
     "shell.execute_reply.started": "2022-04-05T05:26:27.412937Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1459708255124c8d9f35798c44bacf92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indexer2 = StringIndexer(inputCol='ORIGIN',outputCol='ORIGIN_I')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57bf5f79-7953-47ed-908b-9532a8391095",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T05:26:39.405973Z",
     "iopub.status.busy": "2022-04-05T05:26:39.405750Z",
     "iopub.status.idle": "2022-04-05T05:26:39.531181Z",
     "shell.execute_reply": "2022-04-05T05:26:39.530402Z",
     "shell.execute_reply.started": "2022-04-05T05:26:39.405951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38981cbcccf34c9d82a60caeff02231d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indexer3 = StringIndexer(inputCol='DEST',outputCol='DEST_I')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63241f0e-e014-4c3b-bb2d-5ca29584ddd8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# VectorAssembler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c913273d-6df0-46a9-aedd-a2ea46095b55",
   "metadata": {},
   "source": [
    "- Machine Learning models in Spark expects all features in single column. Therefore VectorAssembler combines all features and gives us vector which can be stored in single column. \n",
    "- VectorAssembler expects only Numerical Features, hence we do not take into account 'OP_CARRRIER', 'ORIGIN' and 'DEST'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78656de2-4466-4df3-8655-4baa58460f71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T05:28:24.243063Z",
     "iopub.status.busy": "2022-04-05T05:28:24.242754Z",
     "iopub.status.idle": "2022-04-05T05:28:24.331565Z",
     "shell.execute_reply": "2022-04-05T05:28:24.330872Z",
     "shell.execute_reply.started": "2022-04-05T05:28:24.243030Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3070a289f094c0398b8a176be03b32b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assembler = VectorAssembler(inputCols= ['CRS_DEP_TIME', 'CRS_ARR_TIME', 'CRS_ELAPSED_TIME', 'AIR_TIME', 'DISTANCE', \n",
    "                'MONTH', 'WEEKDAY', 'OP_CARRIER_I', 'ORIGIN_I', 'DEST_I'], outputCol= \"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2652816b-10a0-4623-845f-da87650557b5",
   "metadata": {},
   "source": [
    "# VectorIndexer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0340260b-44ea-4756-939c-0bb2eeab0358",
   "metadata": {},
   "source": [
    "- After VectorAssembler next step is VectorIndexer. \n",
    "- Vector Indexer Automatically identifies categorical features from the feature vector (Output Column of VectorAssembler) and then indexes those categorical features inside vector. \n",
    "- VectorIndexer let usskip OneHotEncoding stage for encoding categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f6750e2-f3ad-4bde-bf8a-d6498bd5e02c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T05:28:38.394055Z",
     "iopub.status.busy": "2022-04-05T05:28:38.393724Z",
     "iopub.status.idle": "2022-04-05T05:28:38.499026Z",
     "shell.execute_reply": "2022-04-05T05:28:38.498295Z",
     "shell.execute_reply.started": "2022-04-05T05:28:38.394019Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703f690802e2475d87f977c7acf21a9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vecindexer = VectorIndexer(inputCol= \"features\", outputCol= \"indexed_features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06670b27-4bff-4386-adcd-cabba70f8059",
   "metadata": {
    "tags": []
   },
   "source": [
    "# StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c1f883-4123-4908-9abd-be943f3b1676",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T06:54:04.731779Z",
     "iopub.status.busy": "2022-04-05T06:54:04.731525Z",
     "iopub.status.idle": "2022-04-05T06:54:04.796056Z",
     "shell.execute_reply": "2022-04-05T06:54:04.795475Z",
     "shell.execute_reply.started": "2022-04-05T06:54:04.731754Z"
    }
   },
   "source": [
    "- StandardScaler scales each value in the feature vector such that the mean is 0 and the standard deviation is 1\n",
    "- It takes parameters:\n",
    "    - withStd: True by default. Scales the data to unit standard deviation\n",
    "    - withMean: False by default. Centers the data with mean before scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18e9f023-3189-4c27-95ec-40e31bda3f00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T05:28:57.746199Z",
     "iopub.status.busy": "2022-04-05T05:28:57.745948Z",
     "iopub.status.idle": "2022-04-05T05:28:57.817909Z",
     "shell.execute_reply": "2022-04-05T05:28:57.817323Z",
     "shell.execute_reply.started": "2022-04-05T05:28:57.746174Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e31b032f6ce4d6f9f41389d273ee09e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stdscaler = StandardScaler(inputCol= \"indexed_features\", outputCol= \"scaledfeatures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b77afd-bcee-481e-9dff-8ab9dfc85d45",
   "metadata": {},
   "source": [
    "# Pipeline Without Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83d7fb0f-d388-4ef1-bac4-78705591f4ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T06:07:03.409298Z",
     "iopub.status.busy": "2022-04-05T06:07:03.409074Z",
     "iopub.status.idle": "2022-04-05T06:07:03.462785Z",
     "shell.execute_reply": "2022-04-05T06:07:03.462181Z",
     "shell.execute_reply.started": "2022-04-05T06:07:03.409274Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b342bd3ae1e949b498a88b288eb74058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import Pipeline from pyspark.ml package\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Build the pipeline object by providing stages(transformers + Estimator) \n",
    "# that you need the dataframe to pass through\n",
    "# Transfoermers - binarizer, bucketizer, indexers, encoder, assembler\n",
    "# Estimator - lr\n",
    "mlppipeline = Pipeline(stages=[indexer1,indexer2,indexer3,assembler,vecindexer,stdscaler])\n",
    "\n",
    "# fit the pipeline for the trainind data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09711660-46c8-44d1-85e7-81422ca018da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T06:07:17.338156Z",
     "iopub.status.busy": "2022-04-05T06:07:17.337727Z",
     "iopub.status.idle": "2022-04-05T06:08:24.862279Z",
     "shell.execute_reply": "2022-04-05T06:08:24.861688Z",
     "shell.execute_reply.started": "2022-04-05T06:07:17.338115Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d47a0027e34990b236b8aeaf3fa726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlppipelinemodel = mlppipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2bd59287-d06b-4300-9e41-3abeb5bfa51e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T06:08:33.004891Z",
     "iopub.status.busy": "2022-04-05T06:08:33.004518Z",
     "iopub.status.idle": "2022-04-05T06:08:33.275109Z",
     "shell.execute_reply": "2022-04-05T06:08:33.274483Z",
     "shell.execute_reply.started": "2022-04-05T06:08:33.004861Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "720e3adbea914f27948b98e99f502cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlppipelinepredicted = mlppipelinemodel.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065f7b1d-0584-4f18-a532-1d176f67d30f",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bdd76177-0fbd-4e49-8d7b-783b695989e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T06:09:13.680041Z",
     "iopub.status.busy": "2022-04-05T06:09:13.679688Z",
     "iopub.status.idle": "2022-04-05T06:09:15.971020Z",
     "shell.execute_reply": "2022-04-05T06:09:15.970359Z",
     "shell.execute_reply.started": "2022-04-05T06:09:13.680002Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e101b2ad464a7fbbb8b934b3918f06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations in training set =  53359203\n",
      "Observations in testing set =  7071817"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "trainDF = mlppipelinepredicted.where(col(\"YEAR\")!=2018)\n",
    "testDF = mlppipelinepredicted.where(col(\"YEAR\")==2018)\n",
    "\n",
    "# print the count of observations in each set\n",
    "print(\"Observations in training set = \", trainDF.count())\n",
    "print(\"Observations in testing set = \", testDF.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8407c0-3892-4de4-a264-1b0544dddb68",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a70476f-2e90-4d60-a344-ea63f1132a4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T06:09:21.190747Z",
     "iopub.status.busy": "2022-04-05T06:09:21.190487Z",
     "iopub.status.idle": "2022-04-05T06:09:21.248310Z",
     "shell.execute_reply": "2022-04-05T06:09:21.247687Z",
     "shell.execute_reply.started": "2022-04-05T06:09:21.190723Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d4bfd03497d4ab3abf8952236e2a003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import the MultilayerPerceptronClassifier function from the pyspark.ml.classification package\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "mlp = MultilayerPerceptronClassifier(layers = [10,5,5,2],featuresCol='scaledfeatures', labelCol='FLIGHT_STATUS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2466a9c-bb37-4789-aee5-7de441e5ecea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T06:09:22.437904Z",
     "iopub.status.busy": "2022-04-05T06:09:22.437671Z",
     "iopub.status.idle": "2022-04-05T06:23:39.968561Z",
     "shell.execute_reply": "2022-04-05T06:23:39.967919Z",
     "shell.execute_reply.started": "2022-04-05T06:09:22.437880Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "013ecea73bb24b2fafe094f3d66de14d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fit the MultilayerPerceptronClassifier object on the training data\n",
    "mlp_model = mlp.fit(trainDF)\n",
    "# #This MultilayerPerceptronClassifier can be used as a transformer to perform prediction on the testing data\n",
    "pred_df = mlp_model.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "988c5e5f-0738-477d-aa6f-871a63a69a22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T06:23:49.458408Z",
     "iopub.status.busy": "2022-04-05T06:23:49.458172Z",
     "iopub.status.idle": "2022-04-05T06:24:42.941981Z",
     "shell.execute_reply": "2022-04-05T06:24:42.940982Z",
     "shell.execute_reply.started": "2022-04-05T06:23:49.458384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ed80c7f0e74417082a4468c70328147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6906218020064716\n",
      "f1: 0.6324285283466642"
     ]
    }
   ],
   "source": [
    "# Build the MulticlassClassificationEvaluator object 'evaluator'\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "# 1. Accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = 'FLIGHT_STATUS', predictionCol = 'prediction', metricName = 'accuracy')\n",
    "# 2. F1 Score (F-measure)\n",
    "evaluator2 = MulticlassClassificationEvaluator(labelCol = 'FLIGHT_STATUS', predictionCol = 'prediction', metricName = 'f1')\n",
    "mlpacc = evaluator.evaluate(pred_df)\n",
    "mlpf1=evaluator2.evaluate(pred_df)\n",
    "print(\"accuracy:\",mlpacc)\n",
    "print('f1:', mlpf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e09230-7b20-46d8-b123-448448a9b199",
   "metadata": {},
   "source": [
    "# Pipeline with model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a13c29d-cc4c-4781-9209-4e7f1eb2dd05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T09:33:33.404345Z",
     "iopub.status.busy": "2022-04-05T09:33:33.404120Z",
     "iopub.status.idle": "2022-04-05T09:33:33.458744Z",
     "shell.execute_reply": "2022-04-05T09:33:33.458100Z",
     "shell.execute_reply.started": "2022-04-05T09:33:33.404321Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d9d98b069148c7a328b34f206d0cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, column,when\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import month,dayofweek,year\n",
    "from pyspark.ml.feature import StringIndexer,VectorAssembler,VectorIndexer,StandardScaler\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb96b19-7f40-41bb-9105-12427aa5a5cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df681ab5-5b25-4d58-9911-d9b3d9e42eb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T09:59:14.586805Z",
     "iopub.status.busy": "2022-04-05T09:59:14.586567Z",
     "iopub.status.idle": "2022-04-05T10:00:52.183307Z",
     "shell.execute_reply": "2022-04-05T10:00:52.182607Z",
     "shell.execute_reply.started": "2022-04-05T09:59:14.586780Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ecfbdf79ae346b88c6e5658c0835a47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\")\\\n",
    "    \t\t.option(\"header\",\"true\")\\\n",
    "    \t\t.option(\"inferschema\",\"true\")\\\n",
    "    \t\t.load('s3://vitaproject23/rawdata/')\n",
    "df=df.drop('Unnamed: 27')\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6aae8c2-3129-446a-b43a-8211ca29669e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T08:48:19.426240Z",
     "iopub.status.busy": "2022-04-05T08:48:19.425858Z",
     "iopub.status.idle": "2022-04-05T08:50:03.234459Z",
     "shell.execute_reply": "2022-04-05T08:50:03.233861Z",
     "shell.execute_reply.started": "2022-04-05T08:48:19.426208Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05da77dae6544e98b458b84029136e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffbe2ab4-3346-4220-b294-ea2c91e53c05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T08:50:15.189427Z",
     "iopub.status.busy": "2022-04-05T08:50:15.189177Z",
     "iopub.status.idle": "2022-04-05T08:50:24.561040Z",
     "shell.execute_reply": "2022-04-05T08:50:24.560217Z",
     "shell.execute_reply.started": "2022-04-05T08:50:15.189394Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc8dec7165bf44f38c53cc7bc98ad17e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61556964"
     ]
    }
   ],
   "source": [
    "CombinedDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e28b4eba-8e6e-4f1d-8dbf-98f43ade0d2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T09:04:36.370052Z",
     "iopub.status.busy": "2022-04-05T09:04:36.369772Z",
     "iopub.status.idle": "2022-04-05T09:04:36.432414Z",
     "shell.execute_reply": "2022-04-05T09:04:36.431762Z",
     "shell.execute_reply.started": "2022-04-05T09:04:36.370027Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8f24c0379246e88af625830ffb4159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def Clean(df):\n",
    "    df=df.where((col(\"CANCELLED\")==0) & (col(\"DIVERTED\")==0))\n",
    "    df=df.drop(\"CANCELLED\",\"CANCELLATION_CODE\",\"DIVERTED\",\"Unnamed: 27\",\"OP_CARRIER_FL_NUM\",\"DEP_TIME\", \"ARR_TIME\")\n",
    "    df=df.withColumn(\"CRS_DEP_TIME\",col(\"CRS_DEP_TIME\")/600).withColumn(\"WHEELS_OFF\",col(\"WHEELS_OFF\")/600).withColumn(\"WHEELS_ON\",col(\"WHEELS_ON\")/600).withColumn(\"CRS_ARR_TIME\",col(\"CRS_ARR_TIME\")/600)\n",
    "    df=df.withColumn(\"CRS_DEP_TIME\",F.col(\"CRS_DEP_TIME\").cast(\"int\")).withColumn(\"WHEELS_OFF\",F.col(\"WHEELS_OFF\").cast(\"int\")).withColumn(\"WHEELS_ON\",F.col(\"WHEELS_ON\").cast(\"int\")).withColumn(\"CRS_ARR_TIME\",F.col(\"CRS_ARR_TIME\").cast(\"int\"))\n",
    "    df = df.withColumn('MONTH',month(df.FL_DATE)).withColumn('WEEKDAY',dayofweek(df.FL_DATE)).withColumn('YEAR',year(df.FL_DATE))\n",
    "    df = df.na.drop()\n",
    "    carrier_name = {'UA':'United Airlines',\n",
    "    'AS':'Alaska Airlines',\n",
    "    '9E':'Endeavor Air',\n",
    "    'B6':'JetBlue Airways',\n",
    "    'EV':'ExpressJet',\n",
    "    'F9':'Frontier Airlines',\n",
    "    'HA':'Hawaiian Airlines',\n",
    "    'MQ':'Envoy Air',\n",
    "    'NK':'Spirit Airlines',\n",
    "    'OO':'SkyWest Airlines',\n",
    "    'VX':'Virgin America',\n",
    "    'WN':'Southwest Airlines',\n",
    "    'YV':'Mesa Airline',\n",
    "    'YX':'Republic Airways',\n",
    "    'AA':'American Airlines',\n",
    "    'US':'US Airways',\n",
    "    'FL':'AirTran Airways Corporation',\n",
    "    'NW':'Northwest Airlines',\n",
    "    'CO':'Continental Air Lines',\n",
    "    'XE':'Expressjet Airlines',\n",
    "    'DL':'Delta Airlines',\n",
    "    'OH':'Comair Airlines',\n",
    "    'G4': 'Allegiant Airlines'}\n",
    "    df = df.na.replace(carrier_name,1)\n",
    "    df = df.withColumn(\"FLIGHT_STATUS\", when(df.ARR_DELAY <= 0 ,0).otherwise(1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e19f4a08-15e1-41d8-9916-8351b7e621c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T09:04:37.641230Z",
     "iopub.status.busy": "2022-04-05T09:04:37.640987Z",
     "iopub.status.idle": "2022-04-05T09:04:37.923343Z",
     "shell.execute_reply": "2022-04-05T09:04:37.922509Z",
     "shell.execute_reply.started": "2022-04-05T09:04:37.641206Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbbf64914d0d46ff9f126f938a6c2428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CleanedDF = Clean(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53a6c07-0fcb-4812-93a9-8b792d9302cb",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2956841c-a0e0-463c-84ee-8b54ef7c58b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T09:32:18.638583Z",
     "iopub.status.busy": "2022-04-05T09:32:18.638357Z",
     "iopub.status.idle": "2022-04-05T09:32:18.916501Z",
     "shell.execute_reply": "2022-04-05T09:32:18.915590Z",
     "shell.execute_reply.started": "2022-04-05T09:32:18.638559Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feabcd5d5b5148b49d58d28fe5a1b2c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def index(df):\n",
    "    df = df.drop('FL_DATE','TAXI_OUT','WHEELS_OFF','WHEELS_ON','TAXI_IN','ARR_DELAY','DEP_DELAY','ACTUAL_ELAPSED_TIME','DEP_TIME','ARR_TIME')\n",
    "    indexer1 = StringIndexer(inputCol='OP_CARRIER',outputCol='OP_CARRIER_I')\n",
    "    indexer2 = StringIndexer(inputCol='ORIGIN',outputCol='ORIGIN_I')\n",
    "    indexer3 = StringIndexer(inputCol='DEST',outputCol='DEST_I')\n",
    "    return indexer3\n",
    "\n",
    "stringindexed = index(CleanedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32f47b4e-3d00-44b8-9bdf-6c84d8f03e8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T09:32:23.959669Z",
     "iopub.status.busy": "2022-04-05T09:32:23.959424Z",
     "iopub.status.idle": "2022-04-05T09:32:24.017103Z",
     "shell.execute_reply": "2022-04-05T09:32:24.016530Z",
     "shell.execute_reply.started": "2022-04-05T09:32:23.959644Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeaa3e37db5f4e39830d02271b9d258b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def assemble():\n",
    "    assembler = VectorAssembler(inputCols= ['CRS_DEP_TIME', 'CRS_ARR_TIME', 'CRS_ELAPSED_TIME', 'AIR_TIME', 'DISTANCE', \n",
    "                'MONTH', 'WEEKDAY', 'OP_CARRIER_I', 'ORIGIN_I', 'DEST_I'], outputCol= \"features\")\n",
    "    \n",
    "    return assembler\n",
    "assembleDF = assemble()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4179d2c3-5575-4c82-a335-e3556eefab63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T09:32:25.248399Z",
     "iopub.status.busy": "2022-04-05T09:32:25.248175Z",
     "iopub.status.idle": "2022-04-05T09:32:25.308635Z",
     "shell.execute_reply": "2022-04-05T09:32:25.308084Z",
     "shell.execute_reply.started": "2022-04-05T09:32:25.248375Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8edc1b72e46b4a9da422c6f8dd16b0cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def vect():\n",
    "    vecindexer = VectorIndexer(inputCol= \"features\", outputCol= \"indexed_features\")\n",
    "    return vecindexer\n",
    "vectindexed = vect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae909ecf-3114-4b75-8289-c3cf7a3ba1e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T09:32:32.123034Z",
     "iopub.status.busy": "2022-04-05T09:32:32.122802Z",
     "iopub.status.idle": "2022-04-05T09:32:32.179824Z",
     "shell.execute_reply": "2022-04-05T09:32:32.179243Z",
     "shell.execute_reply.started": "2022-04-05T09:32:32.123010Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0359630d0674f0fb549c23853037250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def std():\n",
    "    stdscaler = StandardScaler(inputCol= \"indexed_features\", outputCol= \"scaledfeatures\")\n",
    "    return stdscaler\n",
    "stdDF = std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36634fc1-c774-4a6d-8398-10cc80eb2b38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T09:32:33.532336Z",
     "iopub.status.busy": "2022-04-05T09:32:33.532097Z",
     "iopub.status.idle": "2022-04-05T09:32:33.801174Z",
     "shell.execute_reply": "2022-04-05T09:32:33.800445Z",
     "shell.execute_reply.started": "2022-04-05T09:32:33.532311Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "023bc30a676e489e981a5e5c5a14b3f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def model():\n",
    "    mlp = MultilayerPerceptronClassifier(layers = [10,5,5,2],featuresCol='scaledfeatures', labelCol='FLIGHT_STATUS')\n",
    "    return mlp\n",
    "mlpmodel = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "86d5057f-5ce5-4841-a19e-fb3257792fe5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T10:05:53.396819Z",
     "iopub.status.busy": "2022-04-05T10:05:53.396575Z",
     "iopub.status.idle": "2022-04-05T10:05:53.453475Z",
     "shell.execute_reply": "2022-04-05T10:05:53.452886Z",
     "shell.execute_reply.started": "2022-04-05T10:05:53.396795Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d2715ca03214f71827b4d119026940a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline = Pipeline(stages=[CleanedDF])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "39a80576-22c6-4470-85cd-5a0440fae9da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T10:05:54.291330Z",
     "iopub.status.busy": "2022-04-05T10:05:54.291107Z",
     "iopub.status.idle": "2022-04-05T10:05:54.353017Z",
     "shell.execute_reply": "2022-04-05T10:05:54.352318Z",
     "shell.execute_reply.started": "2022-04-05T10:05:54.291306Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "673663af619844de91467ea3de8849ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "Cannot recognize a pipeline stage of type <class 'pyspark.sql.dataframe.DataFrame'>.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/ml/base.py\", line 132, in fit\n",
      "    return self._fit(dataset)\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/ml/pipeline.py\", line 97, in _fit\n",
      "    \"Cannot recognize a pipeline stage of type %s.\" % type(stage))\n",
      "TypeError: Cannot recognize a pipeline stage of type <class 'pyspark.sql.dataframe.DataFrame'>.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipelinedata = pipeline.fit(df)\n",
    "pipeline_data = pipelinedata.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "24c6fc98-8491-447f-a39b-445218f6d063",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T10:01:50.367744Z",
     "iopub.status.busy": "2022-04-05T10:01:50.367521Z",
     "iopub.status.idle": "2022-04-05T10:01:50.638999Z",
     "shell.execute_reply": "2022-04-05T10:01:50.638398Z",
     "shell.execute_reply.started": "2022-04-05T10:01:50.367721Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30ea7ae168b4496891c24999d20a7180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "\"cannot resolve '`YEAR`' given input columns: [FL_DATE, TAXI_OUT, ARR_TIME, ARR_DELAY, DEP_DELAY, DEST, DIVERTED, NAS_DELAY, CANCELLED, LATE_AIRCRAFT_DELAY, WHEELS_ON, OP_CARRIER_FL_NUM, SECURITY_DELAY, CRS_DEP_TIME, CRS_ARR_TIME, DEP_TIME, AIR_TIME, WHEELS_OFF, WEATHER_DELAY, CRS_ELAPSED_TIME, ACTUAL_ELAPSED_TIME, CARRIER_DELAY, DISTANCE, ORIGIN, OP_CARRIER, TAXI_IN, CANCELLATION_CODE];;\\n'Filter NOT ('YEAR = 2018)\\n+- Project [FL_DATE#1276, OP_CARRIER#1277, OP_CARRIER_FL_NUM#1278, ORIGIN#1279, DEST#1280, CRS_DEP_TIME#1281, DEP_TIME#1282, DEP_DELAY#1283, TAXI_OUT#1284, WHEELS_OFF#1285, WHEELS_ON#1286, TAXI_IN#1287, CRS_ARR_TIME#1288, ARR_TIME#1289, ARR_DELAY#1290, CANCELLED#1291, CANCELLATION_CODE#1292, DIVERTED#1293, CRS_ELAPSED_TIME#1294, ACTUAL_ELAPSED_TIME#1295, AIR_TIME#1296, DISTANCE#1297, CARRIER_DELAY#1298, WEATHER_DELAY#1299, ... 3 more fields]\\n   +- Relation[FL_DATE#1276,OP_CARRIER#1277,OP_CARRIER_FL_NUM#1278,ORIGIN#1279,DEST#1280,CRS_DEP_TIME#1281,DEP_TIME#1282,DEP_DELAY#1283,TAXI_OUT#1284,WHEELS_OFF#1285,WHEELS_ON#1286,TAXI_IN#1287,CRS_ARR_TIME#1288,ARR_TIME#1289,ARR_DELAY#1290,CANCELLED#1291,CANCELLATION_CODE#1292,DIVERTED#1293,CRS_ELAPSED_TIME#1294,ACTUAL_ELAPSED_TIME#1295,AIR_TIME#1296,DISTANCE#1297,CARRIER_DELAY#1298,WEATHER_DELAY#1299,... 4 more fields] csv\\n\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py\", line 1367, in filter\n",
      "    jdf = self._jdf.filter(condition._jc)\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py\", line 69, in deco\n",
      "    raise AnalysisException(s.split(': ', 1)[1], stackTrace)\n",
      "pyspark.sql.utils.AnalysisException: \"cannot resolve '`YEAR`' given input columns: [FL_DATE, TAXI_OUT, ARR_TIME, ARR_DELAY, DEP_DELAY, DEST, DIVERTED, NAS_DELAY, CANCELLED, LATE_AIRCRAFT_DELAY, WHEELS_ON, OP_CARRIER_FL_NUM, SECURITY_DELAY, CRS_DEP_TIME, CRS_ARR_TIME, DEP_TIME, AIR_TIME, WHEELS_OFF, WEATHER_DELAY, CRS_ELAPSED_TIME, ACTUAL_ELAPSED_TIME, CARRIER_DELAY, DISTANCE, ORIGIN, OP_CARRIER, TAXI_IN, CANCELLATION_CODE];;\\n'Filter NOT ('YEAR = 2018)\\n+- Project [FL_DATE#1276, OP_CARRIER#1277, OP_CARRIER_FL_NUM#1278, ORIGIN#1279, DEST#1280, CRS_DEP_TIME#1281, DEP_TIME#1282, DEP_DELAY#1283, TAXI_OUT#1284, WHEELS_OFF#1285, WHEELS_ON#1286, TAXI_IN#1287, CRS_ARR_TIME#1288, ARR_TIME#1289, ARR_DELAY#1290, CANCELLED#1291, CANCELLATION_CODE#1292, DIVERTED#1293, CRS_ELAPSED_TIME#1294, ACTUAL_ELAPSED_TIME#1295, AIR_TIME#1296, DISTANCE#1297, CARRIER_DELAY#1298, WEATHER_DELAY#1299, ... 3 more fields]\\n   +- Relation[FL_DATE#1276,OP_CARRIER#1277,OP_CARRIER_FL_NUM#1278,ORIGIN#1279,DEST#1280,CRS_DEP_TIME#1281,DEP_TIME#1282,DEP_DELAY#1283,TAXI_OUT#1284,WHEELS_OFF#1285,WHEELS_ON#1286,TAXI_IN#1287,CRS_ARR_TIME#1288,ARR_TIME#1289,ARR_DELAY#1290,CANCELLED#1291,CANCELLATION_CODE#1292,DIVERTED#1293,CRS_ELAPSED_TIME#1294,ACTUAL_ELAPSED_TIME#1295,AIR_TIME#1296,DISTANCE#1297,CARRIER_DELAY#1298,WEATHER_DELAY#1299,... 4 more fields] csv\\n\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF1 = df.where(col(\"YEAR\")!=2018)\n",
    "testDF1 = df.where(col(\"YEAR\")==2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "638e89de-a001-4fb0-8b27-2179ccc62723",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T06:29:55.151060Z",
     "iopub.status.busy": "2022-04-05T06:29:55.150836Z",
     "iopub.status.idle": "2022-04-05T06:45:46.568344Z",
     "shell.execute_reply": "2022-04-05T06:45:46.567512Z",
     "shell.execute_reply.started": "2022-04-05T06:29:55.151038Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "590d38ae87624dc7bafa41a6bc17013f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipelinemodel = pipeline.fit()\n",
    "pipeline_pred = pipelinemodel.transform(testDF1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1b45393c-8c6c-4325-8e84-53a4fd7e7bef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T06:46:52.644444Z",
     "iopub.status.busy": "2022-04-05T06:46:52.644155Z",
     "iopub.status.idle": "2022-04-05T06:47:01.989312Z",
     "shell.execute_reply": "2022-04-05T06:47:01.979437Z",
     "shell.execute_reply.started": "2022-04-05T06:46:52.644416Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eecafc8e545449d9af5d593c396d9ad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipelinemodel.save(\"s3://minmaxscale/model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15260fd8-24c4-4301-94b6-1139c55eb28a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T05:47:46.950306Z",
     "iopub.status.busy": "2022-04-05T05:47:46.950076Z",
     "iopub.status.idle": "2022-04-05T05:47:49.259993Z",
     "shell.execute_reply": "2022-04-05T05:47:49.259342Z",
     "shell.execute_reply.started": "2022-04-05T05:47:46.950280Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e27421336a482c96edfdc711ec398a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "An error occurred while calling o523.count.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 28 in stage 271.0 failed 4 times, most recent failure: Lost task 28.3 in stage 271.0 (TID 4387, ip-172-31-29-118.ec2.internal, executor 10): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$9: (string) => double)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.agg_doAggregateWithoutKey_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:585)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n",
      "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:127)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:95)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1405)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Unseen label: Republic Airways.  To handle unseen labels, set Param handleInvalid to keep.\n",
      "\tat org.apache.spark.ml.feature.StringIndexerModel$$anonfun$9.apply(StringIndexer.scala:260)\n",
      "\tat org.apache.spark.ml.feature.StringIndexerModel$$anonfun$9.apply(StringIndexer.scala:246)\n",
      "\t... 15 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:2136)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2124)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2123)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2123)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:994)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:994)\n",
      "\tat scala.Option.foreach(Option.scala:257)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:994)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2384)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2333)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2322)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveExecutor.checkNoFailures(AdaptiveExecutor.scala:146)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveExecutor.doRun(AdaptiveExecutor.scala:88)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveExecutor.tryRunningAndGetFuture(AdaptiveExecutor.scala:66)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveExecutor.execute(AdaptiveExecutor.scala:57)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec$$anonfun$finalPhysicalPlan$1.apply(AdaptiveSparkPlanExec.scala:174)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec$$anonfun$finalPhysicalPlan$1.apply(AdaptiveSparkPlanExec.scala:173)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:778)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.finalPhysicalPlan(AdaptiveSparkPlanExec.scala:173)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.executeCollect(AdaptiveSparkPlanExec.scala:180)\n",
      "\tat org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2839)\n",
      "\tat org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2838)\n",
      "\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3391)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.org$apache$spark$sql$execution$SQLExecution$$executeQuery$1(SQLExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1$$anonfun$apply$1.apply(SQLExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecutionMetrics$.withMetrics(QueryExecutionMetrics.scala:141)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.org$apache$spark$sql$execution$SQLExecution$$withMetrics(SQLExecution.scala:178)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:93)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:200)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:92)\n",
      "\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withAction(Dataset.scala:3390)\n",
      "\tat org.apache.spark.sql.Dataset.count(Dataset.scala:2838)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Failed to execute user defined function($anonfun$9: (string) => double)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.agg_doAggregateWithoutKey_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:585)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n",
      "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:127)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:95)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1405)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\t... 1 more\n",
      "Caused by: org.apache.spark.SparkException: Unseen label: Republic Airways.  To handle unseen labels, set Param handleInvalid to keep.\n",
      "\tat org.apache.spark.ml.feature.StringIndexerModel$$anonfun$9.apply(StringIndexer.scala:260)\n",
      "\tat org.apache.spark.ml.feature.StringIndexerModel$$anonfun$9.apply(StringIndexer.scala:246)\n",
      "\t... 15 more\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py\", line 525, in count\n",
      "    return int(self._jdf.count())\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
      "    format(target_id, \".\", name), value)\n",
      "py4j.protocol.Py4JJavaError: An error occurred while calling o523.count.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 28 in stage 271.0 failed 4 times, most recent failure: Lost task 28.3 in stage 271.0 (TID 4387, ip-172-31-29-118.ec2.internal, executor 10): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$9: (string) => double)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.agg_doAggregateWithoutKey_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:585)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n",
      "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:127)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:95)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1405)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Unseen label: Republic Airways.  To handle unseen labels, set Param handleInvalid to keep.\n",
      "\tat org.apache.spark.ml.feature.StringIndexerModel$$anonfun$9.apply(StringIndexer.scala:260)\n",
      "\tat org.apache.spark.ml.feature.StringIndexerModel$$anonfun$9.apply(StringIndexer.scala:246)\n",
      "\t... 15 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:2136)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2124)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2123)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2123)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:994)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:994)\n",
      "\tat scala.Option.foreach(Option.scala:257)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:994)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2384)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2333)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2322)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveExecutor.checkNoFailures(AdaptiveExecutor.scala:146)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveExecutor.doRun(AdaptiveExecutor.scala:88)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveExecutor.tryRunningAndGetFuture(AdaptiveExecutor.scala:66)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveExecutor.execute(AdaptiveExecutor.scala:57)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec$$anonfun$finalPhysicalPlan$1.apply(AdaptiveSparkPlanExec.scala:174)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec$$anonfun$finalPhysicalPlan$1.apply(AdaptiveSparkPlanExec.scala:173)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:778)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.finalPhysicalPlan(AdaptiveSparkPlanExec.scala:173)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.executeCollect(AdaptiveSparkPlanExec.scala:180)\n",
      "\tat org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2839)\n",
      "\tat org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2838)\n",
      "\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3391)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.org$apache$spark$sql$execution$SQLExecution$$executeQuery$1(SQLExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1$$anonfun$apply$1.apply(SQLExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecutionMetrics$.withMetrics(QueryExecutionMetrics.scala:141)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.org$apache$spark$sql$execution$SQLExecution$$withMetrics(SQLExecution.scala:178)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:93)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:200)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:92)\n",
      "\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withAction(Dataset.scala:3390)\n",
      "\tat org.apache.spark.sql.Dataset.count(Dataset.scala:2838)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Failed to execute user defined function($anonfun$9: (string) => double)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.agg_doAggregateWithoutKey_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:585)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n",
      "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:127)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:95)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1405)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\t... 1 more\n",
      "Caused by: org.apache.spark.SparkException: Unseen label: Republic Airways.  To handle unseen labels, set Param handleInvalid to keep.\n",
      "\tat org.apache.spark.ml.feature.StringIndexerModel$$anonfun$9.apply(StringIndexer.scala:260)\n",
      "\tat org.apache.spark.ml.feature.StringIndexerModel$$anonfun$9.apply(StringIndexer.scala:246)\n",
      "\t... 15 more\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Build the BinaryClassificationEvaluator object 'evaluator'\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "\n",
    "# Calculate the accracy and print its value\n",
    "accuracy = mlppipelinepredicted.filter(mlppipelinepredicted.FLIGHT_STATUS == mlppipelinepredicted.prediction).count()/float(mlppipelinepredicted.count())\n",
    "print(\"Accuracy = \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981446fc-61b6-4cf4-b69e-be97b3ccecc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
