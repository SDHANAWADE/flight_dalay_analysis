{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d05a96c-7a75-46d4-a04e-3163771da0d4",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e1eedf2-5ec1-45e1-93c5-91cea18f463e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T06:06:46.063764Z",
     "iopub.status.busy": "2022-04-05T06:06:46.063396Z",
     "iopub.status.idle": "2022-04-05T06:06:53.374366Z",
     "shell.execute_reply": "2022-04-05T06:06:53.373788Z",
     "shell.execute_reply.started": "2022-04-05T06:06:46.063722Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b90fcf8445244877bb8609738faa73af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = spark.read.format(\"parquet\")\\\n",
    "    .option(\"header\",\"true\")\\\n",
    "    .option(\"inferschema\",\"true\")\\\n",
    "    .load(\"s3://vitaproject23/cleandata/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0c6b8d-3021-4554-9c66-7720b254a761",
   "metadata": {},
   "source": [
    "# Drop Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0783975-e893-4b4e-b22f-c39561ea8744",
   "metadata": {},
   "source": [
    "Our aim is to predict delay at the time of Ticket booking and hence the following columns wont help us in prediction because customer will be unaware of the following data :- 'TAXI_OUT', 'TAXI_IN', 'WHEELS_OFF', 'WHEELS_ON', 'ARR_DELAY', 'DEP_DELAY', 'ACTUAL_ELAPSED_TIME', 'DEP_TIME', 'ARR_TIME'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebb18203-d331-4566-a23b-1c78d1895470",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T06:06:57.089315Z",
     "iopub.status.busy": "2022-04-05T06:06:57.089083Z",
     "iopub.status.idle": "2022-04-05T06:06:57.153213Z",
     "shell.execute_reply": "2022-04-05T06:06:57.152651Z",
     "shell.execute_reply.started": "2022-04-05T06:06:57.089292Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d0f69a7e43a433b9c4c6e916a239ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.drop('FL_DATE','TAXI_OUT','WHEELS_OFF','WHEELS_ON','TAXI_IN','ARR_DELAY','DEP_DELAY','ACTUAL_ELAPSED_TIME','DEP_TIME','ARR_TIME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6471ea64-eb61-41f0-ad78-9b807a239889",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T05:25:42.284983Z",
     "iopub.status.busy": "2022-04-05T05:25:42.284760Z",
     "iopub.status.idle": "2022-04-05T05:25:45.623642Z",
     "shell.execute_reply": "2022-04-05T05:25:45.622917Z",
     "shell.execute_reply.started": "2022-04-05T05:25:42.284960Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55feb6b52c0c46ec92d4df896ca42ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Columns:  12\n",
      "Number of Rows: 60431020"
     ]
    }
   ],
   "source": [
    "df.columns\n",
    "print(\"Number of Columns: \", len(df.columns))\n",
    "print(\"Number of Rows:\", df.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8e4857-4933-4d59-8272-f44a2dfbd36c",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fac54bd3-f054-4167-b696-9e3d879e6f76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T06:02:54.061725Z",
     "iopub.status.busy": "2022-04-05T06:02:54.061480Z",
     "iopub.status.idle": "2022-04-05T06:02:54.118804Z",
     "shell.execute_reply": "2022-04-05T06:02:54.118207Z",
     "shell.execute_reply.started": "2022-04-05T06:02:54.061702Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0a63bb0b16a4dd599a2004d356fbf46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer,VectorAssembler,VectorIndexer,StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad219a4-3125-4784-9990-d11f3099f6c1",
   "metadata": {},
   "source": [
    "# StringIndexer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0fa4c6-6037-42d5-a9f1-7ad7b7fc5ee2",
   "metadata": {},
   "source": [
    "- Converting Categorical Columns such as 'OP_CARRIER', 'ORIGIN', 'DEST' are converted into Indexed Columns 'OP_CARRIER_I', 'ORIGIN_I', 'DEST_I' using StringIndexer.\n",
    "- StringIndexer is used to convert categorical columns to numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abf81191-982c-4893-b645-0676be82cf7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T05:26:08.460879Z",
     "iopub.status.busy": "2022-04-05T05:26:08.460548Z",
     "iopub.status.idle": "2022-04-05T05:26:08.777218Z",
     "shell.execute_reply": "2022-04-05T05:26:08.776393Z",
     "shell.execute_reply.started": "2022-04-05T05:26:08.460841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee9de40989a4427b9c5c865a6b6b2cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indexer1 = StringIndexer(inputCol='OP_CARRIER',outputCol='OP_CARRIER_I')\n",
    "#strindexedDF1 = indexer1.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf5ee044-6ef1-4a6c-9dcd-47d660531ff9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T05:26:27.412962Z",
     "iopub.status.busy": "2022-04-05T05:26:27.412738Z",
     "iopub.status.idle": "2022-04-05T05:26:27.477788Z",
     "shell.execute_reply": "2022-04-05T05:26:27.477221Z",
     "shell.execute_reply.started": "2022-04-05T05:26:27.412937Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1459708255124c8d9f35798c44bacf92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indexer2 = StringIndexer(inputCol='ORIGIN',outputCol='ORIGIN_I')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57bf5f79-7953-47ed-908b-9532a8391095",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T05:26:39.405973Z",
     "iopub.status.busy": "2022-04-05T05:26:39.405750Z",
     "iopub.status.idle": "2022-04-05T05:26:39.531181Z",
     "shell.execute_reply": "2022-04-05T05:26:39.530402Z",
     "shell.execute_reply.started": "2022-04-05T05:26:39.405951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38981cbcccf34c9d82a60caeff02231d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indexer3 = StringIndexer(inputCol='DEST',outputCol='DEST_I')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63241f0e-e014-4c3b-bb2d-5ca29584ddd8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# VectorAssembler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c913273d-6df0-46a9-aedd-a2ea46095b55",
   "metadata": {},
   "source": [
    "- Machine Learning models in Spark expects all features in single column. Therefore VectorAssembler combines all features and gives us vector which can be stored in single column. \n",
    "- VectorAssembler expects only Numerical Features, hence we do not take into account 'OP_CARRRIER', 'ORIGIN' and 'DEST'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78656de2-4466-4df3-8655-4baa58460f71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T05:28:24.243063Z",
     "iopub.status.busy": "2022-04-05T05:28:24.242754Z",
     "iopub.status.idle": "2022-04-05T05:28:24.331565Z",
     "shell.execute_reply": "2022-04-05T05:28:24.330872Z",
     "shell.execute_reply.started": "2022-04-05T05:28:24.243030Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3070a289f094c0398b8a176be03b32b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "assembler = VectorAssembler(inputCols= ['CRS_DEP_TIME', 'CRS_ARR_TIME', 'CRS_ELAPSED_TIME', 'AIR_TIME', 'DISTANCE', \n",
    "                'MONTH', 'WEEKDAY', 'OP_CARRIER_I', 'ORIGIN_I', 'DEST_I'], outputCol= \"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2652816b-10a0-4623-845f-da87650557b5",
   "metadata": {},
   "source": [
    "# VectorIndexer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0340260b-44ea-4756-939c-0bb2eeab0358",
   "metadata": {},
   "source": [
    "- After VectorAssembler next step is VectorIndexer. \n",
    "- Vector Indexer Automatically identifies categorical features from the feature vector (Output Column of VectorAssembler) and then indexes those categorical features inside vector. \n",
    "- VectorIndexer let usskip OneHotEncoding stage for encoding categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f6750e2-f3ad-4bde-bf8a-d6498bd5e02c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T05:28:38.394055Z",
     "iopub.status.busy": "2022-04-05T05:28:38.393724Z",
     "iopub.status.idle": "2022-04-05T05:28:38.499026Z",
     "shell.execute_reply": "2022-04-05T05:28:38.498295Z",
     "shell.execute_reply.started": "2022-04-05T05:28:38.394019Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "703f690802e2475d87f977c7acf21a9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vecindexer = VectorIndexer(inputCol= \"features\", outputCol= \"indexed_features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06670b27-4bff-4386-adcd-cabba70f8059",
   "metadata": {
    "tags": []
   },
   "source": [
    "# StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c1f883-4123-4908-9abd-be943f3b1676",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T06:54:04.731779Z",
     "iopub.status.busy": "2022-04-05T06:54:04.731525Z",
     "iopub.status.idle": "2022-04-05T06:54:04.796056Z",
     "shell.execute_reply": "2022-04-05T06:54:04.795475Z",
     "shell.execute_reply.started": "2022-04-05T06:54:04.731754Z"
    }
   },
   "source": [
    "- StandardScaler scales each value in the feature vector such that the mean is 0 and the standard deviation is 1\n",
    "- It takes parameters:\n",
    "    - withStd: True by default. Scales the data to unit standard deviation\n",
    "    - withMean: False by default. Centers the data with mean before scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18e9f023-3189-4c27-95ec-40e31bda3f00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T05:28:57.746199Z",
     "iopub.status.busy": "2022-04-05T05:28:57.745948Z",
     "iopub.status.idle": "2022-04-05T05:28:57.817909Z",
     "shell.execute_reply": "2022-04-05T05:28:57.817323Z",
     "shell.execute_reply.started": "2022-04-05T05:28:57.746174Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e31b032f6ce4d6f9f41389d273ee09e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stdscaler = StandardScaler(inputCol= \"indexed_features\", outputCol= \"scaledfeatures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b77afd-bcee-481e-9dff-8ab9dfc85d45",
   "metadata": {},
   "source": [
    "# Pipeline Without Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83d7fb0f-d388-4ef1-bac4-78705591f4ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T06:07:03.409298Z",
     "iopub.status.busy": "2022-04-05T06:07:03.409074Z",
     "iopub.status.idle": "2022-04-05T06:07:03.462785Z",
     "shell.execute_reply": "2022-04-05T06:07:03.462181Z",
     "shell.execute_reply.started": "2022-04-05T06:07:03.409274Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b342bd3ae1e949b498a88b288eb74058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import Pipeline from pyspark.ml package\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Build the pipeline object by providing stages(transformers + Estimator) \n",
    "# that you need the dataframe to pass through\n",
    "# Transfoermers - binarizer, bucketizer, indexers, encoder, assembler\n",
    "# Estimator - lr\n",
    "mlppipeline = Pipeline(stages=[indexer1,indexer2,indexer3,assembler,vecindexer,stdscaler])\n",
    "\n",
    "# fit the pipeline for the trainind data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09711660-46c8-44d1-85e7-81422ca018da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T06:07:17.338156Z",
     "iopub.status.busy": "2022-04-05T06:07:17.337727Z",
     "iopub.status.idle": "2022-04-05T06:08:24.862279Z",
     "shell.execute_reply": "2022-04-05T06:08:24.861688Z",
     "shell.execute_reply.started": "2022-04-05T06:07:17.338115Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d47a0027e34990b236b8aeaf3fa726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlppipelinemodel = mlppipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2bd59287-d06b-4300-9e41-3abeb5bfa51e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T06:08:33.004891Z",
     "iopub.status.busy": "2022-04-05T06:08:33.004518Z",
     "iopub.status.idle": "2022-04-05T06:08:33.275109Z",
     "shell.execute_reply": "2022-04-05T06:08:33.274483Z",
     "shell.execute_reply.started": "2022-04-05T06:08:33.004861Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "720e3adbea914f27948b98e99f502cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlppipelinepredicted = mlppipelinemodel.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065f7b1d-0584-4f18-a532-1d176f67d30f",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bdd76177-0fbd-4e49-8d7b-783b695989e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T06:09:13.680041Z",
     "iopub.status.busy": "2022-04-05T06:09:13.679688Z",
     "iopub.status.idle": "2022-04-05T06:09:15.971020Z",
     "shell.execute_reply": "2022-04-05T06:09:15.970359Z",
     "shell.execute_reply.started": "2022-04-05T06:09:13.680002Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e101b2ad464a7fbbb8b934b3918f06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations in training set =  53359203\n",
      "Observations in testing set =  7071817"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "trainDF = mlppipelinepredicted.where(col(\"YEAR\")!=2018)\n",
    "testDF = mlppipelinepredicted.where(col(\"YEAR\")==2018)\n",
    "\n",
    "# print the count of observations in each set\n",
    "print(\"Observations in training set = \", trainDF.count())\n",
    "print(\"Observations in testing set = \", testDF.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8407c0-3892-4de4-a264-1b0544dddb68",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a70476f-2e90-4d60-a344-ea63f1132a4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T06:09:21.190747Z",
     "iopub.status.busy": "2022-04-05T06:09:21.190487Z",
     "iopub.status.idle": "2022-04-05T06:09:21.248310Z",
     "shell.execute_reply": "2022-04-05T06:09:21.247687Z",
     "shell.execute_reply.started": "2022-04-05T06:09:21.190723Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d4bfd03497d4ab3abf8952236e2a003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import the MultilayerPerceptronClassifier function from the pyspark.ml.classification package\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "mlp = MultilayerPerceptronClassifier(layers = [10,5,5,2],featuresCol='scaledfeatures', labelCol='FLIGHT_STATUS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2466a9c-bb37-4789-aee5-7de441e5ecea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T06:09:22.437904Z",
     "iopub.status.busy": "2022-04-05T06:09:22.437671Z",
     "iopub.status.idle": "2022-04-05T06:23:39.968561Z",
     "shell.execute_reply": "2022-04-05T06:23:39.967919Z",
     "shell.execute_reply.started": "2022-04-05T06:09:22.437880Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "013ecea73bb24b2fafe094f3d66de14d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fit the MultilayerPerceptronClassifier object on the training data\n",
    "mlp_model = mlp.fit(trainDF)\n",
    "# #This MultilayerPerceptronClassifier can be used as a transformer to perform prediction on the testing data\n",
    "pred_df = mlp_model.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "988c5e5f-0738-477d-aa6f-871a63a69a22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T06:23:49.458408Z",
     "iopub.status.busy": "2022-04-05T06:23:49.458172Z",
     "iopub.status.idle": "2022-04-05T06:24:42.941981Z",
     "shell.execute_reply": "2022-04-05T06:24:42.940982Z",
     "shell.execute_reply.started": "2022-04-05T06:23:49.458384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ed80c7f0e74417082a4468c70328147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6906218020064716\n",
      "f1: 0.6324285283466642"
     ]
    }
   ],
   "source": [
    "# Build the MulticlassClassificationEvaluator object 'evaluator'\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "# 1. Accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = 'FLIGHT_STATUS', predictionCol = 'prediction', metricName = 'accuracy')\n",
    "# 2. F1 Score (F-measure)\n",
    "evaluator2 = MulticlassClassificationEvaluator(labelCol = 'FLIGHT_STATUS', predictionCol = 'prediction', metricName = 'f1')\n",
    "mlpacc = evaluator.evaluate(pred_df)\n",
    "mlpf1=evaluator2.evaluate(pred_df)\n",
    "print(\"accuracy:\",mlpacc)\n",
    "print('f1:', mlpf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e09230-7b20-46d8-b123-448448a9b199",
   "metadata": {},
   "source": [
    "# Pipeline with model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "36634fc1-c774-4a6d-8398-10cc80eb2b38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T06:28:38.569649Z",
     "iopub.status.busy": "2022-04-05T06:28:38.569303Z",
     "iopub.status.idle": "2022-04-05T06:28:45.930844Z",
     "shell.execute_reply": "2022-04-05T06:28:45.930078Z",
     "shell.execute_reply.started": "2022-04-05T06:28:38.569608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "310c46da7a5c4c89a6567242cee17c84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = spark.read.format(\"parquet\")\\\n",
    "    .option(\"header\",\"true\")\\\n",
    "    .option(\"inferschema\",\"true\")\\\n",
    "    .load(\"s3://vitaproject23/cleandata/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c897a2b-e245-487d-ab44-dfb7c9791b96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T06:28:50.743170Z",
     "iopub.status.busy": "2022-04-05T06:28:50.742911Z",
     "iopub.status.idle": "2022-04-05T06:28:50.801174Z",
     "shell.execute_reply": "2022-04-05T06:28:50.800606Z",
     "shell.execute_reply.started": "2022-04-05T06:28:50.743144Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35cde314140d476d9ddecbb2ca8a1a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = df.drop('FL_DATE','TAXI_OUT','WHEELS_OFF','WHEELS_ON','TAXI_IN','ARR_DELAY','DEP_DELAY','ACTUAL_ELAPSED_TIME','DEP_TIME','ARR_TIME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9c8db563-347a-4271-9bc7-b9f2c895a581",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T06:29:37.807481Z",
     "iopub.status.busy": "2022-04-05T06:29:37.807119Z",
     "iopub.status.idle": "2022-04-05T06:29:38.090866Z",
     "shell.execute_reply": "2022-04-05T06:29:38.089859Z",
     "shell.execute_reply.started": "2022-04-05T06:29:37.807427Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10ed6abd83c743ed8e90d38e0e624ec2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainDF1 = df.where(col(\"YEAR\")!=2018)\n",
    "testDF1 = df.where(col(\"YEAR\")==2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4d2e5e89-0da3-48de-8582-e04bb87e21d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T06:29:41.970746Z",
     "iopub.status.busy": "2022-04-05T06:29:41.970524Z",
     "iopub.status.idle": "2022-04-05T06:29:42.034433Z",
     "shell.execute_reply": "2022-04-05T06:29:42.033836Z",
     "shell.execute_reply.started": "2022-04-05T06:29:41.970724Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7927758987634a38b61834616f5a986b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline = Pipeline(stages=[indexer1,indexer2,indexer3,assembler,vecindexer,stdscaler,mlp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "638e89de-a001-4fb0-8b27-2179ccc62723",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T06:29:55.151060Z",
     "iopub.status.busy": "2022-04-05T06:29:55.150836Z",
     "iopub.status.idle": "2022-04-05T06:45:46.568344Z",
     "shell.execute_reply": "2022-04-05T06:45:46.567512Z",
     "shell.execute_reply.started": "2022-04-05T06:29:55.151038Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "590d38ae87624dc7bafa41a6bc17013f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipelinemodel = pipeline.fit(trainDF1)\n",
    "pipeline_pred = pipelinemodel.transform(testDF1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1b45393c-8c6c-4325-8e84-53a4fd7e7bef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T06:46:52.644444Z",
     "iopub.status.busy": "2022-04-05T06:46:52.644155Z",
     "iopub.status.idle": "2022-04-05T06:47:01.989312Z",
     "shell.execute_reply": "2022-04-05T06:47:01.979437Z",
     "shell.execute_reply.started": "2022-04-05T06:46:52.644416Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eecafc8e545449d9af5d593c396d9ad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipelinemodel.save(\"s3://minmaxscale/model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15260fd8-24c4-4301-94b6-1139c55eb28a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-05T05:47:46.950306Z",
     "iopub.status.busy": "2022-04-05T05:47:46.950076Z",
     "iopub.status.idle": "2022-04-05T05:47:49.259993Z",
     "shell.execute_reply": "2022-04-05T05:47:49.259342Z",
     "shell.execute_reply.started": "2022-04-05T05:47:46.950280Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e27421336a482c96edfdc711ec398a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An error was encountered:\n",
      "An error occurred while calling o523.count.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 28 in stage 271.0 failed 4 times, most recent failure: Lost task 28.3 in stage 271.0 (TID 4387, ip-172-31-29-118.ec2.internal, executor 10): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$9: (string) => double)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.agg_doAggregateWithoutKey_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:585)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n",
      "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:127)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:95)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1405)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Unseen label: Republic Airways.  To handle unseen labels, set Param handleInvalid to keep.\n",
      "\tat org.apache.spark.ml.feature.StringIndexerModel$$anonfun$9.apply(StringIndexer.scala:260)\n",
      "\tat org.apache.spark.ml.feature.StringIndexerModel$$anonfun$9.apply(StringIndexer.scala:246)\n",
      "\t... 15 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:2136)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2124)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2123)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2123)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:994)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:994)\n",
      "\tat scala.Option.foreach(Option.scala:257)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:994)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2384)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2333)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2322)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveExecutor.checkNoFailures(AdaptiveExecutor.scala:146)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveExecutor.doRun(AdaptiveExecutor.scala:88)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveExecutor.tryRunningAndGetFuture(AdaptiveExecutor.scala:66)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveExecutor.execute(AdaptiveExecutor.scala:57)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec$$anonfun$finalPhysicalPlan$1.apply(AdaptiveSparkPlanExec.scala:174)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec$$anonfun$finalPhysicalPlan$1.apply(AdaptiveSparkPlanExec.scala:173)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:778)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.finalPhysicalPlan(AdaptiveSparkPlanExec.scala:173)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.executeCollect(AdaptiveSparkPlanExec.scala:180)\n",
      "\tat org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2839)\n",
      "\tat org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2838)\n",
      "\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3391)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.org$apache$spark$sql$execution$SQLExecution$$executeQuery$1(SQLExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1$$anonfun$apply$1.apply(SQLExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecutionMetrics$.withMetrics(QueryExecutionMetrics.scala:141)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.org$apache$spark$sql$execution$SQLExecution$$withMetrics(SQLExecution.scala:178)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:93)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:200)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:92)\n",
      "\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withAction(Dataset.scala:3390)\n",
      "\tat org.apache.spark.sql.Dataset.count(Dataset.scala:2838)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Failed to execute user defined function($anonfun$9: (string) => double)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.agg_doAggregateWithoutKey_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:585)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n",
      "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:127)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:95)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1405)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\t... 1 more\n",
      "Caused by: org.apache.spark.SparkException: Unseen label: Republic Airways.  To handle unseen labels, set Param handleInvalid to keep.\n",
      "\tat org.apache.spark.ml.feature.StringIndexerModel$$anonfun$9.apply(StringIndexer.scala:260)\n",
      "\tat org.apache.spark.ml.feature.StringIndexerModel$$anonfun$9.apply(StringIndexer.scala:246)\n",
      "\t... 15 more\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py\", line 525, in count\n",
      "    return int(self._jdf.count())\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\", line 1257, in __call__\n",
      "    answer, self.gateway_client, self.target_id, self.name)\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/utils.py\", line 63, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\", line 328, in get_return_value\n",
      "    format(target_id, \".\", name), value)\n",
      "py4j.protocol.Py4JJavaError: An error occurred while calling o523.count.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 28 in stage 271.0 failed 4 times, most recent failure: Lost task 28.3 in stage 271.0 (TID 4387, ip-172-31-29-118.ec2.internal, executor 10): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$9: (string) => double)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.agg_doAggregateWithoutKey_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:585)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n",
      "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:127)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:95)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1405)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Unseen label: Republic Airways.  To handle unseen labels, set Param handleInvalid to keep.\n",
      "\tat org.apache.spark.ml.feature.StringIndexerModel$$anonfun$9.apply(StringIndexer.scala:260)\n",
      "\tat org.apache.spark.ml.feature.StringIndexerModel$$anonfun$9.apply(StringIndexer.scala:246)\n",
      "\t... 15 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:2136)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2124)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:2123)\n",
      "\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2123)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:994)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:994)\n",
      "\tat scala.Option.foreach(Option.scala:257)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:994)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2384)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2333)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2322)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveExecutor.checkNoFailures(AdaptiveExecutor.scala:146)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveExecutor.doRun(AdaptiveExecutor.scala:88)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveExecutor.tryRunningAndGetFuture(AdaptiveExecutor.scala:66)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveExecutor.execute(AdaptiveExecutor.scala:57)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec$$anonfun$finalPhysicalPlan$1.apply(AdaptiveSparkPlanExec.scala:174)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec$$anonfun$finalPhysicalPlan$1.apply(AdaptiveSparkPlanExec.scala:173)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:778)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.finalPhysicalPlan(AdaptiveSparkPlanExec.scala:173)\n",
      "\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.executeCollect(AdaptiveSparkPlanExec.scala:180)\n",
      "\tat org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2839)\n",
      "\tat org.apache.spark.sql.Dataset$$anonfun$count$1.apply(Dataset.scala:2838)\n",
      "\tat org.apache.spark.sql.Dataset$$anonfun$52.apply(Dataset.scala:3391)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.org$apache$spark$sql$execution$SQLExecution$$executeQuery$1(SQLExecution.scala:83)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1$$anonfun$apply$1.apply(SQLExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecutionMetrics$.withMetrics(QueryExecutionMetrics.scala:141)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.org$apache$spark$sql$execution$SQLExecution$$withMetrics(SQLExecution.scala:178)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:93)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:200)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:92)\n",
      "\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withAction(Dataset.scala:3390)\n",
      "\tat org.apache.spark.sql.Dataset.count(Dataset.scala:2838)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: org.apache.spark.SparkException: Failed to execute user defined function($anonfun$9: (string) => double)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.agg_doAggregateWithoutKey_0$(Unknown Source)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:585)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409)\n",
      "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:127)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:95)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1405)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\t... 1 more\n",
      "Caused by: org.apache.spark.SparkException: Unseen label: Republic Airways.  To handle unseen labels, set Param handleInvalid to keep.\n",
      "\tat org.apache.spark.ml.feature.StringIndexerModel$$anonfun$9.apply(StringIndexer.scala:260)\n",
      "\tat org.apache.spark.ml.feature.StringIndexerModel$$anonfun$9.apply(StringIndexer.scala:246)\n",
      "\t... 15 more\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Build the BinaryClassificationEvaluator object 'evaluator'\n",
    "evaluator = BinaryClassificationEvaluator()\n",
    "\n",
    "# Calculate the accracy and print its value\n",
    "accuracy = mlppipelinepredicted.filter(mlppipelinepredicted.FLIGHT_STATUS == mlppipelinepredicted.prediction).count()/float(mlppipelinepredicted.count())\n",
    "print(\"Accuracy = \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981446fc-61b6-4cf4-b69e-be97b3ccecc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
